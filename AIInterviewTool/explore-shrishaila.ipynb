{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in /home/shri123/projects/freelancer_auto/server/venv/lib/python3.8/site-packages (3.10.4)\n",
      "Requirement already satisfied: typing-extensions in /home/shri123/projects/freelancer_auto/server/venv/lib/python3.8/site-packages (from SpeechRecognition) (4.12.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/shri123/projects/freelancer_auto/server/venv/lib/python3.8/site-packages (from SpeechRecognition) (2.31.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/shri123/projects/freelancer_auto/server/venv/lib/python3.8/site-packages (from requests>=2.26.0->SpeechRecognition) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/shri123/projects/freelancer_auto/server/venv/lib/python3.8/site-packages (from requests>=2.26.0->SpeechRecognition) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/shri123/projects/freelancer_auto/server/venv/lib/python3.8/site-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/shri123/projects/freelancer_auto/server/venv/lib/python3.8/site-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SpeechRecognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/your/audio_file.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m recognizer \u001b[38;5;241m=\u001b[39m sr\u001b[38;5;241m.\u001b[39mRecognizer()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Read the audio file\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mAudioFile(audio_file_path) \u001b[38;5;28;01mas\u001b[39;00m source:\n\u001b[1;32m     11\u001b[0m     audio \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecord(source)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Use Google Speech Recognition\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/freelancer_auto/server/venv/lib/python3.8/site-packages/speech_recognition/__init__.py:241\u001b[0m, in \u001b[0;36mAudioFile.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis audio source is already inside a context manager\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# attempt to read the file as WAV\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudio_reader \u001b[38;5;241m=\u001b[39m \u001b[43mwave\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename_or_fileobject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlittle_endian \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# RIFF WAV is a little-endian format (most ``audioop`` operations assume that the frames are stored in little-endian form)\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (wave\u001b[38;5;241m.\u001b[39mError, \u001b[38;5;167;01mEOFError\u001b[39;00m):\n",
      "File \u001b[0;32m/usr/lib/python3.8/wave.py:510\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    508\u001b[0m         mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWave_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Wave_write(f)\n",
      "File \u001b[0;32m/usr/lib/python3.8/wave.py:160\u001b[0m, in \u001b[0;36mWave_read.__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_i_opened_the_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 160\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_i_opened_the_file \u001b[38;5;241m=\u001b[39m f\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# else, assume it is an open file object already\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/your/audio_file.wav'"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# Define the audio file path\n",
    "audio_file_path = \"/path/to/your/audio_file.wav\"\n",
    "\n",
    "# Initialize the recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Read the audio file\n",
    "with sr.AudioFile(audio_file_path) as source:\n",
    "    audio = recognizer.record(source)\n",
    "\n",
    "# Use Google Speech Recognition\n",
    "try:\n",
    "    transcription = recognizer.recognize_google(audio, key=None)  # Pass your API key if needed\n",
    "    print(\"Transcription: \" + transcription)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand the audio.\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GOOGLE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Open the audio file in binary read mode\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(audio_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m audio_file:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Call the API to transcribe the audio\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mGOOGLE\u001b[49m\u001b[38;5;241m.\u001b[39mAudio\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     13\u001b[0m         audio\u001b[38;5;241m=\u001b[39maudio_file,\n\u001b[1;32m     14\u001b[0m         content_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio/ogg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Get the transcription from the response\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     transcription \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtranscription\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GOOGLE' is not defined"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "GOOGLE_API_KEY = 'AIzaSyAvmM4no4AP-ClN-QSwbEORvG7oqxaFpn4'\n",
    "\n",
    "# Define the audio file path\n",
    "audio_file_path = \"/home/shri123/projects/AIInterviewTool/q1.ogg\"\n",
    "\n",
    "# Open the audio file in binary read mode\n",
    "with open(audio_file_path, \"rb\") as audio_file:\n",
    "    # Call the API to transcribe the audio\n",
    "    response = GOOGLE.Audio.create(\n",
    "        audio=audio_file,\n",
    "        content_type=\"audio/ogg\"\n",
    "    )\n",
    "\n",
    "    # Get the transcription from the response\n",
    "    transcription = response['transcription']\n",
    "\n",
    "# Print the transcription result\n",
    "print(transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\" This is a recording of a candidate preparing for interview, please provide feedback on how they can improve to impress the interviewer. \\n {transcription.text}\"\n",
    "\n",
    "\n",
    "import requests\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "api_key = os.environ['GOOGLE_API_KEY']\n",
    "\n",
    "# Set the API endpoint and API key.\n",
    "endpoint = \"https://generativelanguage.googleapis.com/v1beta\"\n",
    "# Prepare the request body.\n",
    "request_body = {\n",
    "    \"contents\": [\n",
    "        {\n",
    "            \"parts\": [\n",
    "                {\n",
    "                    \"text\": prompt\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Make the request.\n",
    "response = requests.post(\n",
    "    f\"{endpoint}/models/gemini-pro:generateContent?key={api_key}\",\n",
    "    json=request_body,\n",
    ")\n",
    "\n",
    "# Parse the response.\n",
    "response_json = response.json()\n",
    "\n",
    "generated_content = response_json[\"candidates\"][0]['content']['parts'][0]['text']\n",
    "\n",
    "# Print the generated content.\n",
    "print(generated_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "audio_file= open(\"/home/vivek/projects/interview_tool/shrishaila/What are your strengths and weaknesses.ogg\", \"rb\")\n",
    "transcription = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file\n",
    ")\n",
    "print(transcription.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\" This is a recording of a candidate preparing for interview, please provide feedback on how they can improve to impress the interviewer. \\n {transcription.text}\"\n",
    "\n",
    "\n",
    "import requests\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "api_key = os.environ['GOOGLE_API_KEY']\n",
    "\n",
    "# Set the API endpoint and API key.\n",
    "endpoint = \"https://generativelanguage.googleapis.com/v1beta\"\n",
    "# Prepare the request body.\n",
    "request_body = {\n",
    "    \"contents\": [\n",
    "        {\n",
    "            \"parts\": [\n",
    "                {\n",
    "                    \"text\": prompt\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Make the request.\n",
    "response = requests.post(\n",
    "    f\"{endpoint}/models/gemini-pro:generateContent?key={api_key}\",\n",
    "    json=request_body,\n",
    ")\n",
    "\n",
    "# Parse the response.\n",
    "response_json = response.json()\n",
    "\n",
    "generated_content = response_json[\"candidates\"][0]['content']['parts'][0]['text']\n",
    "\n",
    "# Print the generated content.\n",
    "print(generated_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
