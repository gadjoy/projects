{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_title = \"\"\"Ai tools\"\"\"\n",
    "quries_num = \"\"\"1\"\"\"\n",
    "Level = \"\"\"Easy\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. What are some of the challenges of using AI tools?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Set API endpoint\n",
    "load_dotenv()\n",
    "api_key = os.getenv('GOOGLE_API_KEY')\n",
    "endpoint = \"https://generativelanguage.googleapis.com/v1beta2\"\n",
    "\n",
    "# generate the prompt to get my proposal\n",
    "prompt = f\"\"\"\n",
    "\n",
    "INPUT:\n",
    "\n",
    "Role: You are an expert in generating interview questions for academic positions with a strong understanding of the client's vision.\n",
    "\n",
    "Context: The client's requirements for a software project are analyzed. You have a solid understanding of their needs.\n",
    "\n",
    "Level: Based on the chosen level, provide questions to help the user improve their skills.\n",
    "\n",
    "Please generate {quries_num} interview questions for the topic {topic_title} suitable for an {Level} level interview.\n",
    "\n",
    "Topic Choosen: {topic_title}\n",
    "Number of Questions: {quries_num}\n",
    "\n",
    "Based on the user number of questions and the topic chosen, you will generate the same number of questions in the list with the index from 1. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# prepare the request body\n",
    "request_body = {\n",
    "    \"prompt\": {\n",
    "        \"text\": prompt\n",
    "    }\n",
    "}\n",
    "\n",
    "# make the request to generative language api\n",
    "response = requests.post(f\"{endpoint}/models/text-bison-001:generateText?key={api_key}\", json=request_body)\n",
    "questions = response.json()['candidates'][0]['output']\n",
    "print(f\"\\n{questions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are some of the challenges of using AI tools?\"\n",
    "answer = \"well actualy I cam not sure about the answer, please can you hire me with this interview, but I will make sure that I will nevwer let you or your company down with my beahviour\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Feedback:**\n",
      "\n",
      "The candidate's response to the question \"What are some of the challenges of using AI tools?\" was not very good. They did not provide a clear answer to the question, and they did not seem to be very knowledgeable about the topic.\n",
      "\n",
      "**How to improve:**\n",
      "\n",
      "The candidate could improve their response by doing some research on the topic of AI challenges. They could also read some articles or books on the subject, or watch some videos. They could also talk to people who are knowledgeable about AI challenges.\n",
      "\n",
      "**Where the candidate gave a good answer:**\n",
      "\n",
      "The candidate did not give a good answer to the question, but they did say that they would never let the interviewer or the company down with their behavior. This is a good answer, because it shows that the candidate is committed to their work.\n",
      "\n",
      "**Where the candidate went wrong:**\n",
      "\n",
      "The candidate went wrong by not providing a clear answer to the question. They also did not seem to be very knowledgeable about the topic of AI challenges.\n",
      "\n",
      "**Suggestions for improvement:**\n",
      "\n",
      "The candidate could improve their response by doing some research on the topic of AI challenges. They could also read some articles or books on the subject, or watch some videos. They could also talk to people who are knowledgeable about AI challenges.\n",
      "\n",
      "**Additional tips:**\n",
      "\n",
      "When answering a question in an interview, it is important to be prepared. This means doing some research on the topic of the question. It is also important to be confident in your answer. If you are not sure about the answer, it is better to say that you are not sure than to give a wrong answer.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key from .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv('GOOGLE_API_KEY')\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found. Please set the GOOGLE_API_KEY in the .env file.\")\n",
    "\n",
    "# Set API endpoint\n",
    "endpoint = \"https://generativelanguage.googleapis.com/v1beta2/models/text-bison-001:generateText\"\n",
    "\n",
    "# Construct the AI answer based on the provided answer and query\n",
    "AI_answer = f\"\"\"\n",
    "Provide feedback on the candidate's response. Please take the {query} as the question which is beign answer by the interview candidate. \n",
    "And take {answer} as the as the answer for the {query} which is asked in intherview. Focus on:\n",
    "- provide feedback on how they can improve to impress the interviewer.\n",
    "- How to improve their response\n",
    "- Where the candidate gave a good answer\n",
    "- Where they went wrong\n",
    "- Suggestions for improvement\n",
    "- Additional tips\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Prepare the request body\n",
    "request_body = {\n",
    "    \"prompt\": {\n",
    "        \"text\": AI_answer\n",
    "    }\n",
    "}\n",
    "\n",
    "# Make the request to the generative language API\n",
    "response = requests.post(f\"{endpoint}?key={api_key}\", json=request_body)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    feedback = response.json().get('candidates', [{}])[0].get('output', 'No feedback received.')\n",
    "    print(feedback)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m audio_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/shri123/projects/AIInterviewTool/q1.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Open the audio file in binary read mode\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maudio_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m audio_file:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Call the API to transcribe the audio\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mAudio\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     13\u001b[0m         audio\u001b[38;5;241m=\u001b[39maudio_file,\n\u001b[1;32m     14\u001b[0m         content_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio/mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Get the transcription from the response\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = 'AIzaSyAvmM4no4AP-ClN-QSwbEORvG7oqxaFpn4'\n",
    "\n",
    "# Get the audio file path from the user\n",
    "audio_file_path = input(\"/home/shri123/projects/AIInterviewTool/q1.mp3\")\n",
    "\n",
    "# Open the audio file in binary read mode\n",
    "with open(audio_file_path, \"rb\") as audio_file:\n",
    "    # Call the API to transcribe the audio\n",
    "    response = openai.Audio.create(\n",
    "        audio=audio_file,\n",
    "        content_type=\"audio/mp4\"\n",
    "    )\n",
    "\n",
    "    # Get the transcription from the response\n",
    "    transcription = response['transcription']\n",
    "\n",
    "# Print the transcription result\n",
    "print(transcription)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
