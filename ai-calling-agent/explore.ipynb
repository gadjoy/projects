{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/rao/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "PortAudio library not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msignal\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic_settings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSettings, SettingsConfigDict\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvocode\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_streaming_microphone_input_and_speaker_output\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvocode\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m configure_pretty_logging\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvocode\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstreaming\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_gpt_agent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatGPTAgent\n",
      "File \u001b[0;32m~/projects/ai-calling-agent/.venv/lib/python3.10/site-packages/vocode/helpers.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Optional, Tuple, Union\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msounddevice\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mloguru\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logger\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvocode\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstreaming\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_device\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmicrophone_input\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     MicrophoneInput \u001b[38;5;28;01mas\u001b[39;00m StreamingMicrophoneInput,\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m~/projects/ai-calling-agent/.venv/lib/python3.10/site-packages/sounddevice.py:71\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPortAudio library not found\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     72\u001b[0m     _lib \u001b[38;5;241m=\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mdlopen(_libname)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[0;31mOSError\u001b[0m: PortAudio library not found"
     ]
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "import signal\n",
    "\n",
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "\n",
    "from vocode.helpers import create_streaming_microphone_input_and_speaker_output\n",
    "from vocode.logging import configure_pretty_logging\n",
    "from vocode.streaming.agent.chat_gpt_agent import ChatGPTAgent\n",
    "from vocode.streaming.models.agent import ChatGPTAgentConfig\n",
    "from vocode.streaming.models.message import BaseMessage\n",
    "from vocode.streaming.models.synthesizer import AzureSynthesizerConfig\n",
    "from vocode.streaming.models.transcriber import (\n",
    "    DeepgramTranscriberConfig,\n",
    "    PunctuationEndpointingConfig,\n",
    ")\n",
    "from vocode.streaming.streaming_conversation import StreamingConversation\n",
    "from vocode.streaming.synthesizer.azure_synthesizer import AzureSynthesizer\n",
    "from vocode.streaming.transcriber.deepgram_transcriber import DeepgramTranscriber\n",
    "\n",
    "configure_pretty_logging()\n",
    "\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    \"\"\"\n",
    "    Settings for the streaming conversation quickstart.\n",
    "    These parameters can be configured with environment variables.\n",
    "    \"\"\"\n",
    "\n",
    "    openai_api_key: str = \"ENTER_YOUR_OPENAI_API_KEY_HERE\"\n",
    "    azure_speech_key: str = \"ENTER_YOUR_AZURE_KEY_HERE\"\n",
    "    deepgram_api_key: str = \"ENTER_YOUR_DEEPGRAM_API_KEY_HERE\"\n",
    "\n",
    "    azure_speech_region: str = \"eastus\"\n",
    "\n",
    "    # This means a .env file can be used to overload these settings\n",
    "    # ex: \"OPENAI_API_KEY=my_key\" will set openai_api_key over the default above\n",
    "    model_config = SettingsConfigDict(\n",
    "        env_file=\".env\",\n",
    "        env_file_encoding=\"utf-8\",\n",
    "        extra=\"ignore\",\n",
    "    )\n",
    "\n",
    "\n",
    "settings = Settings()\n",
    "\n",
    "\n",
    "async def main():\n",
    "    (\n",
    "        microphone_input,\n",
    "        speaker_output,\n",
    "    ) = create_streaming_microphone_input_and_speaker_output(\n",
    "        use_default_devices=False,\n",
    "    )\n",
    "\n",
    "    conversation = StreamingConversation(\n",
    "        output_device=speaker_output,\n",
    "        transcriber=DeepgramTranscriber(\n",
    "            DeepgramTranscriberConfig.from_input_device(\n",
    "                microphone_input,\n",
    "                endpointing_config=PunctuationEndpointingConfig(),\n",
    "                api_key=settings.deepgram_api_key,\n",
    "            ),\n",
    "        ),\n",
    "        agent=ChatGPTAgent(\n",
    "            ChatGPTAgentConfig(\n",
    "                openai_api_key=settings.openai_api_key,\n",
    "                initial_message=BaseMessage(text=\"What up\"),\n",
    "                prompt_preamble=\"\"\"The AI is having a pleasant conversation about life\"\"\",\n",
    "            )\n",
    "        ),\n",
    "        synthesizer=AzureSynthesizer(\n",
    "            AzureSynthesizerConfig.from_output_device(speaker_output),\n",
    "            azure_speech_key=settings.azure_speech_key,\n",
    "            azure_speech_region=settings.azure_speech_region,\n",
    "        ),\n",
    "    )\n",
    "    await conversation.start()\n",
    "    print(\"Conversation started, press Ctrl+C to end\")\n",
    "    signal.signal(signal.SIGINT, lambda _0, _1: asyncio.create_task(conversation.terminate()))\n",
    "    while conversation.is_active():\n",
    "        chunk = await microphone_input.get_audio()\n",
    "        conversation.receive_audio(chunk)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/rao/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "PortAudio library not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msignal\u001b[39;00m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic_settings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSettings, SettingsConfigDict\n",
      "\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvocode\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_streaming_microphone_input_and_speaker_output\n",
      "\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvocode\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m configure_pretty_logging\n",
      "\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvocode\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstreaming\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_gpt_agent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatGPTAgent\n",
      "\n",
      "File \u001b[0;32m~/projects/ai-calling-agent/.venv/lib/python3.10/site-packages/vocode/helpers.py:4\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Optional, Tuple, Union\n",
      "\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msounddevice\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msd\u001b[39;00m\n",
      "\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mloguru\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logger\n",
      "\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvocode\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstreaming\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_device\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmicrophone_input\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "\u001b[1;32m      8\u001b[0m     MicrophoneInput \u001b[38;5;28;01mas\u001b[39;00m StreamingMicrophoneInput,\n",
      "\u001b[1;32m      9\u001b[0m )\n",
      "\n",
      "File \u001b[0;32m~/projects/ai-calling-agent/.venv/lib/python3.10/site-packages/sounddevice.py:71\u001b[0m\n",
      "\u001b[1;32m     69\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m---> 71\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPortAudio library not found\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;32m     72\u001b[0m     _lib \u001b[38;5;241m=\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mdlopen(_libname)\n",
      "\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\n",
      "\u001b[0;31mOSError\u001b[0m: PortAudio library not found"
     ]
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "import signal\n",
    "\n",
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "\n",
    "from vocode.helpers import create_streaming_microphone_input_and_speaker_output\n",
    "from vocode.logging import configure_pretty_logging\n",
    "from vocode.streaming.agent.chat_gpt_agent import ChatGPTAgent\n",
    "from vocode.streaming.models.agent import ChatGPTAgentConfig\n",
    "from vocode.streaming.models.message import BaseMessage\n",
    "from vocode.streaming.models.synthesizer import AzureSynthesizerConfig\n",
    "from vocode.streaming.models.transcriber import (\n",
    "    DeepgramTranscriberConfig,\n",
    "    PunctuationEndpointingConfig,\n",
    ")\n",
    "from vocode.streaming.streaming_conversation import StreamingConversation\n",
    "from vocode.streaming.synthesizer.azure_synthesizer import AzureSynthesizer\n",
    "from vocode.streaming.transcriber.deepgram_transcriber import DeepgramTranscriber\n",
    "\n",
    "configure_pretty_logging()\n",
    "\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    \"\"\"\n",
    "    Settings for the streaming conversation quickstart.\n",
    "    These parameters can be configured with environment variables.\n",
    "    \"\"\"\n",
    "\n",
    "    openai_api_key: str = \"ENTER_YOUR_OPENAI_API_KEY_HERE\"\n",
    "    azure_speech_key: str = \"ENTER_YOUR_AZURE_KEY_HERE\"\n",
    "    deepgram_api_key: str = \"ENTER_YOUR_DEEPGRAM_API_KEY_HERE\"\n",
    "\n",
    "    azure_speech_region: str = \"eastus\"\n",
    "\n",
    "    # This means a .env file can be used to overload these settings\n",
    "    # ex: \"OPENAI_API_KEY=my_key\" will set openai_api_key over the default above\n",
    "    model_config = SettingsConfigDict(\n",
    "        env_file=\".env\",\n",
    "        env_file_encoding=\"utf-8\",\n",
    "        extra=\"ignore\",\n",
    "    )\n",
    "\n",
    "\n",
    "settings = Settings()\n",
    "\n",
    "\n",
    "async def main():\n",
    "    (\n",
    "        microphone_input,\n",
    "        speaker_output,\n",
    "    ) = create_streaming_microphone_input_and_speaker_output(\n",
    "        use_default_devices=False,\n",
    "    )\n",
    "\n",
    "    conversation = StreamingConversation(\n",
    "        output_device=speaker_output,\n",
    "        transcriber=DeepgramTranscriber(\n",
    "            DeepgramTranscriberConfig.from_input_device(\n",
    "                microphone_input,\n",
    "                endpointing_config=PunctuationEndpointingConfig(),\n",
    "                api_key=settings.deepgram_api_key,\n",
    "            ),\n",
    "        ),\n",
    "        agent=ChatGPTAgent(\n",
    "            ChatGPTAgentConfig(\n",
    "                openai_api_key=settings.openai_api_key,\n",
    "                initial_message=BaseMessage(text=\"What up\"),\n",
    "                prompt_preamble=\"\"\"The AI is having a pleasant conversation about life\"\"\",\n",
    "            )\n",
    "        ),\n",
    "        synthesizer=AzureSynthesizer(\n",
    "            AzureSynthesizerConfig.from_output_device(speaker_output),\n",
    "            azure_speech_key=settings.azure_speech_key,\n",
    "            azure_speech_region=settings.azure_speech_region,\n",
    "        ),\n",
    "    )\n",
    "    await conversation.start()\n",
    "    print(\"Conversation started, press Ctrl+C to end\")\n",
    "    signal.signal(signal.SIGINT, lambda _0, _1: asyncio.create_task(conversation.terminate()))\n",
    "    while conversation.is_active():\n",
    "        chunk = await microphone_input.get_audio()\n",
    "        conversation.receive_audio(chunk)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/rao/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "PortAudio library not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msignal\u001b[39;00m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic_settings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSettings, SettingsConfigDict\n",
      "\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvocode\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_streaming_microphone_input_and_speaker_output\n",
      "\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvocode\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m configure_pretty_logging\n",
      "\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvocode\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstreaming\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_gpt_agent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatGPTAgent\n",
      "\n",
      "File \u001b[0;32m~/projects/ai-calling-agent/.venv/lib/python3.10/site-packages/vocode/helpers.py:4\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m\n",
      "\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Optional, Tuple, Union\n",
      "\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msounddevice\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msd\u001b[39;00m\n",
      "\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mloguru\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logger\n",
      "\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvocode\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstreaming\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_device\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmicrophone_input\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "\u001b[1;32m      8\u001b[0m     MicrophoneInput \u001b[38;5;28;01mas\u001b[39;00m StreamingMicrophoneInput,\n",
      "\u001b[1;32m      9\u001b[0m )\n",
      "\n",
      "File \u001b[0;32m~/projects/ai-calling-agent/.venv/lib/python3.10/site-packages/sounddevice.py:71\u001b[0m\n",
      "\u001b[1;32m     69\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m---> 71\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPortAudio library not found\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;32m     72\u001b[0m     _lib \u001b[38;5;241m=\u001b[39m _ffi\u001b[38;5;241m.\u001b[39mdlopen(_libname)\n",
      "\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\n",
      "\u001b[0;31mOSError\u001b[0m: PortAudio library not found"
     ]
    }
   ],
   "source": [
    "\n",
    "import asyncio\n",
    "import signal\n",
    "\n",
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "\n",
    "from vocode.helpers import create_streaming_microphone_input_and_speaker_output\n",
    "from vocode.logging import configure_pretty_logging\n",
    "from vocode.streaming.agent.chat_gpt_agent import ChatGPTAgent\n",
    "from vocode.streaming.models.agent import ChatGPTAgentConfig\n",
    "from vocode.streaming.models.message import BaseMessage\n",
    "from vocode.streaming.models.synthesizer import AzureSynthesizerConfig\n",
    "from vocode.streaming.models.transcriber import (\n",
    "    DeepgramTranscriberConfig,\n",
    "    PunctuationEndpointingConfig,\n",
    ")\n",
    "from vocode.streaming.streaming_conversation import StreamingConversation\n",
    "from vocode.streaming.synthesizer.azure_synthesizer import AzureSynthesizer\n",
    "from vocode.streaming.transcriber.deepgram_transcriber import DeepgramTranscriber\n",
    "\n",
    "configure_pretty_logging()\n",
    "\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    \"\"\"\n",
    "    Settings for the streaming conversation quickstart.\n",
    "    These parameters can be configured with environment variables.\n",
    "    \"\"\"\n",
    "\n",
    "    openai_api_key: str = \"ENTER_YOUR_OPENAI_API_KEY_HERE\"\n",
    "    azure_speech_key: str = \"ENTER_YOUR_AZURE_KEY_HERE\"\n",
    "    deepgram_api_key: str = \"ENTER_YOUR_DEEPGRAM_API_KEY_HERE\"\n",
    "\n",
    "    azure_speech_region: str = \"eastus\"\n",
    "\n",
    "    # This means a .env file can be used to overload these settings\n",
    "    # ex: \"OPENAI_API_KEY=my_key\" will set openai_api_key over the default above\n",
    "    model_config = SettingsConfigDict(\n",
    "        env_file=\".env\",\n",
    "        env_file_encoding=\"utf-8\",\n",
    "        extra=\"ignore\",\n",
    "    )\n",
    "\n",
    "\n",
    "settings = Settings()\n",
    "\n",
    "\n",
    "async def main():\n",
    "    (\n",
    "        microphone_input,\n",
    "        speaker_output,\n",
    "    ) = create_streaming_microphone_input_and_speaker_output(\n",
    "        use_default_devices=False,\n",
    "    )\n",
    "\n",
    "    conversation = StreamingConversation(\n",
    "        output_device=speaker_output,\n",
    "        transcriber=DeepgramTranscriber(\n",
    "            DeepgramTranscriberConfig.from_input_device(\n",
    "                microphone_input,\n",
    "                endpointing_config=PunctuationEndpointingConfig(),\n",
    "                api_key=settings.deepgram_api_key,\n",
    "            ),\n",
    "        ),\n",
    "        agent=ChatGPTAgent(\n",
    "            ChatGPTAgentConfig(\n",
    "                openai_api_key=settings.openai_api_key,\n",
    "                initial_message=BaseMessage(text=\"What up\"),\n",
    "                prompt_preamble=\"\"\"The AI is having a pleasant conversation about life\"\"\",\n",
    "            )\n",
    "        ),\n",
    "        synthesizer=AzureSynthesizer(\n",
    "            AzureSynthesizerConfig.from_output_device(speaker_output),\n",
    "            azure_speech_key=settings.azure_speech_key,\n",
    "            azure_speech_region=settings.azure_speech_region,\n",
    "        ),\n",
    "    )\n",
    "    await conversation.start()\n",
    "    print(\"Conversation started, press Ctrl+C to end\")\n",
    "    signal.signal(signal.SIGINT, lambda _0, _1: asyncio.create_task(conversation.terminate()))\n",
    "    while conversation.is_active():\n",
    "        chunk = await microphone_input.get_audio()\n",
    "        conversation.receive_audio(chunk)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\":\"Unauthorized\",\"statusCode\":401}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.aicaller.io/v1/phoneCalls\"\n",
    "\n",
    "payload = {\n",
    "    \"teamId\": \"363573667364666473667332\",\n",
    "    \"phoneNumberId\": \"363573667364666473667332\",\n",
    "    \"callTemplateId\": \"363573667364666473667332\",\n",
    "    \"nameOfHuman\": \"Vivek\",\n",
    "    \"toPhoneNumber\": \"+919738126623\",\n",
    "    \"toEmailAddress\": \"vivekanandb@hotmail.com\",\n",
    "    \"status\": \"queued\",\n",
    "    \"promptVariableValues\": [\n",
    "        {\n",
    "            \"key\": \"customer_name\",\n",
    "            \"value\": \"Arpit\"\n",
    "        },\n",
    "        # {\n",
    "        #     \"key\": \"business_name\",\n",
    "        #     \"value\": \"Squaw Valley Plumbing Co\"\n",
    "        # },\n",
    "        # {\n",
    "        #     \"key\": \"services_provided\",\n",
    "        #     \"value\": \"Plumbing services\"\n",
    "        # },\n",
    "        # {\n",
    "        #     \"key\": \"hours_of_operation\",\n",
    "        #     \"value\": \"Monday through Saturday 9am-7pm, Sunday 10am-2pm\"\n",
    "        # },\n",
    "        # {\n",
    "        #     \"key\": \"employees\",\n",
    "        #     \"value\": \"Around 10 plumbers on staff, and a team of support people\"\n",
    "        # },\n",
    "        # {\n",
    "        #     \"key\": \"owner_contact\",\n",
    "        #     \"value\": \"Michael Shelly, phone number 8781086645\"\n",
    "        # }\n",
    "    ],\n",
    "    \"record\": True,\n",
    "#     \"task\": \"Your name is Vivek, and you’re a surveyor working on behalf of a small business directory. You joined the company earlier this year. The company’s goal is to collect data about small businesses and create a proprietary dataset to sell to private equity funds. Your job is to ask four basic questions, and collect the information from that small business.\\n\\nThe four questions you need to answer are:\\n1. The business’ category and what services it provides\\n2. The business’ hours of operation\\n3. The business’ size (how many employees and customers it has)\\n\\nHere’s an example dialogue\\nPerson: Hello this is Squaw Valley Plumbing Co, my name is Arpit, how can I help you?\\nYou: Hi Arpit, this is Vivek, I’m calling on behalf of a local small business directory. I wanted to create a listing for your company - do you have time to help?\\nPerson: Yeah absolutely. Just to make sure though, you’re making a local directory? What do you need to know?\\nYou: Yes, we collect this information on a semi-annual basis to understand the state and overall health of small businesses in the valley. I just have a list of questions to go through.\\nPerson: Sounds good, go for it.\\nYou: Awesome. First question is: what services do you all provide to the community?\\nPerson: We provide plumbing services. Most of the time it’s folks calling in because they have an issue with their sink or toilet. You know how it is.\\nYou: Right, yeah. Second question is: what are your hours of operations?\\nPerson: Monday through Saturday it’s 9am-7pm. And then Sundays it’s 10am-2pm.\\nYou: Do you observe federal holidays?\\nPerson: Yes of course.\\nYou: Okay, perfect. And at this point, could you give me a sense of how long you’ve been serving our community for?\\nPerson: We opened up shop about ten years ago. Feels like we’ve been in the valley forever.\\nYou: Haha I’m sure. And at this point, how large have you all gotten? Could you give me a sense of how many folks you’re currently employing?\\nPerson: Yeah we’ve gotten pretty big. We have around 10 plumbers on staff, and then a team of support people working around them.\\nYou: Fantastic, that’s great to hear. Last question is: could you share the owner’s contact information with me? We won’t give this info out, but it helps us if we need to follow up and collect more info. \\nPerson: Eh, I’m not sure if I’m comfortable doing that\\nYou: Yeah no worries, it’s completely up to you. We have a few programs we offer to small businesses in the area, and if you qualify it’s just easier to reach out direct. But again, no worries at all if you don’t feel comfortable sharing.\\nPerson: Oh, that’s fine then. The owner’s name is Michael Shelly and his phone number is 8781086645.\\nYou: Perfect, thanks so much for your help.\\nPerson: Of course! Goodbye.\"\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"aicaller-api-key\": \"668538fc8fce2ef47907b012\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.aicaller.io/v1/phoneCalls\"\n",
    "\n",
    "payload = {\n",
    "    \"teamId\": \"363573667364666473667332\",\n",
    "    \"phoneNumberId\": \"363573667364666473667332\",\n",
    "    \"callTemplateId\": \"363573667364666473667332\",\n",
    "    \"nameOfHuman\": \"John\",\n",
    "    \"toPhoneNumber\": \"+1234567890\",\n",
    "    \"toEmailAddress\": \"someone@email.com\",\n",
    "    \"status\": \"queued\",\n",
    "    \"promptVariableValues\": [\n",
    "        {\n",
    "            \"key\": \"customer_name\",\n",
    "            \"value\": \"John\"\n",
    "        }\n",
    "    ],\n",
    "    \"record\": True\n",
    "}\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "response = requests.request(\"POST\", url, json=payload, headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\":{\"_id\":\"668540838fce2ef47907b103\",\"teamId\":\"668532958fce2ef47907ae37\",\"phoneNumberId\":\"1\",\"callTemplateId\":\"668532968fce2ef47907ae47\",\"nameOfHuman\":\"John\",\"toPhoneNumber\":\"+918076376842\",\"status\":\"queued\",\"isPremiumVoice\":false,\"promptVariableValues\":[],\"record\":true,\"customTagsHitOnCall\":[],\"rawTextConversation\":[],\"callOrigin\":\"api\",\"createdAt\":\"2024-07-03T12:13:55.089Z\",\"updatedAt\":\"2024-07-03T12:13:55.089Z\"}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.aicaller.io/v1/phoneCalls\"\n",
    "\n",
    "payload = {\n",
    "    \"callTemplateId\": \"668532968fce2ef47907ae47\",\n",
    "    \"nameOfHuman\": \"John\",\n",
    "    \"toPhoneNumber\": \"+918076376842\",\n",
    "    \"teamId\": \"668532958fce2ef47907ae37\",\n",
    "    \"promptVariableValues\": [\n",
    "        {\n",
    "            \"key\": \"customer_name\",\n",
    "            \"value\": \"John\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "headers = {\n",
    "    \"aicaller-api-key\": \"NjY4NTNmOGE4ZmNlMmVmNDc5MDdiMDNhOktKUFRqZWJzTWhTMjA0UG9YS0Fjd0M0TDVLSFJNeWgx\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, json=payload, headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
